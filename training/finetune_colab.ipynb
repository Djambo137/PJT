{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade transformers>=4.44.0 peft>=0.11.0 accelerate>=1.0.0 datasets>=2.20.0 \\\n    pillow>=10.4.0 opencv-python-headless>=4.10.0 jsonschema>=4.22.0 pymupdf>=1.24.9 pytesseract>=0.3.13 bitsandbytes\n",
    "try:\n",
    "    import bitsandbytes  # noqa: F401\n",
    "except Exception as e:\n",
    "    print(\"bitsandbytes unavailable, training will fall back to FP16\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('/content/fiche-idee-global-vlm'):\n",
    "    !git clone https://github.com/placeholder/fiche-idee-global-vlm.git\n",
    "%cd /content/fiche-idee-global-vlm\n",
    "!pip install -q -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "vision_dir = Path('data/vision_crops')\n",
    "images = sorted(vision_dir.glob('*.*'))\n",
    "print(f'Found {len(images)} images')\n",
    "for img_path in images[:2]:\n",
    "    display(Image.open(img_path).resize((320, 320)))\n",
    "if not images:\n",
    "    print('Drop ~16 fiche crops into data/vision_crops/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build JSONL skeleton + annotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/make_multiview_jsonl.py --images-dir data/vision_crops --output data/json_data/multiview_dataset.jsonl\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from PIL import Image\n",
    "dspath = Path('data/json_data/multiview_dataset.jsonl')\n",
    "records = [json.loads(l) for l in dspath.read_text(encoding='utf-8').splitlines() if l.strip()]\n",
    "print(f'Records ready: {len(records)}')\n",
    "\n",
    "# Minimal inline annotator\n",
    "idx = 0  # change index per fiche\n",
    "rec = records[idx]\n",
    "print(rec['images'])\n",
    "for p in rec['images']:\n",
    "    display(Image.open(p).resize((320,320)))\n",
    "print('Current output:', json.dumps(rec['output'], indent=2, ensure_ascii=False))\n",
    "# Edit below then save\n",
    "rec['output'] = rec['output']  # <- replace with your filled JSON\n",
    "records[idx] = rec\n",
    "with dspath.open('w', encoding='utf-8') as f:\n",
    "    for r in records:\n",
    "        f.write(json.dumps(r, ensure_ascii=False) + '\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python training/train_qwen2vl_lora.py --jsonl data/json_data/multiview_dataset.jsonl --model Qwen/Qwen2-VL-2B-Instruct --output-dir outputs/qwen_lora_adapter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test + export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python inference/predict_json.py --images data/vision_crops/sample.png --context \"\" --instruction default --adapter outputs/qwen_lora_adapter --output outputs/sample_pred.json\n",
    "!python inference/json_to_openscad.py outputs/sample_pred.json --out outputs/sample.scad\n",
    "from pathlib import Path\n",
    "print(Path('outputs/sample_pred.json').read_text()[:1000])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
